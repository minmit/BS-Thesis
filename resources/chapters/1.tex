
\فصل{مقدمات}

در این بخش، به معرفی برخی از مفاهیمی می‌پردازیم که در این رساله استفاده شده‌اند.

\قسمت{کلاس‌های پیچیدگی}

مهم‌ترین کلاس‌های پیچیدگی در ادامه معرفی شده‌اند. پیش از آن، گفتنی است به یک مسئله که پاسخ آن \بلی{} یا \خیر{} باشد، مسئله‌ی \کج{تصمیم‌گیری}\زیرنوشت{Decision Problem} گفته می‌شود.

\مهم{کلاس پیچیدگی \پی{}}: مجموعه‌ای از مسئله‌های تصمیم‌گیری که برای آن‌ها الگوریتم (قطعی) با زمان اجرای چند‌جمله‌ای وجود دارد.

\مهم{کلاس پیچیدگی \ان‌پی{}}: مجموعه‌ای از مسئله‌های تصمیم‌گیری که وقتی به ازای یک ورودی، پاسخ \بلی{} باشد، این ادعا را می‌توان در زمان چند‌جمله‌ای ثابت کرد.

با توجه به تعاریف ارائه شده، بدیهی است که $P \subseteq NP$. یک پرسش بسیار مشهور است این است که آیا $P = NP$ یا خیر؟ در حال حاضر، حدس بسیار قوی در رابطه با پاسخ این پرسش این است که \ان‌پی{} با \پی{} برابر نیست.

\مهم{کلاس پیچیدگی \سخت{}}\زیرنوشت{$NP$-Hard}: مجموعه‌ی مسئله‌هایی است که در صورت حل شدن یکی از آن‌ها در زمان چند‌جمله‌ای، همه‌ی مسئله‌های \ان‌پی{} در زمان چند‌جمله‌ای حل خواهند شد. پس با فرض $NP \neq P$، هیچ یک از مسئله‌های \سخت{}، الگوریتم چند‌جمله‌ای ندارند. شایان ذکر است که برخی از مسئله‌های \سخت{} ممکن است مسئله‌ی تصمیم‌گیری نباشند.

\مهم{کلاس پیچیدگی \کامل{}}\زیرنوشت{$NP$-Complete}: مجموعه‌ی مسئله‌هایی است که هم \ان‌پی{} و هم \سخت{} باشند.

\قسمت{الگوریتم‌های تقریبی}

مسئله‌های بهینه‌سازی گسسته، مسئله‌هایی هستند که در آن‌ها هدف، کمینه کردن هزینه (یا بیشینه کردن سود) است. اکثر مسئله‌های مورد توجه در این مجموعه، مسئله‌های هستند که \سخت{} بودن آن‌ها نشان داده شده‌است و در نتیجه، با این فرض که $NP \neq P$، نمی‌توان برای یافتن پاسخ بهینه‌ی چنین مسئله‌هایی، راه حلی کارا ارائه کرد.

نظر به دشواری یافتن پاسخ بهینه‌ی چنین مسئله‌هایی، یک رویکرد رایج، ارائه‌ی الگوریتم‌های کارایی است که پاسخی نه چندان دور از پاسخ بهینه می‌یابند. به چنین الگوریتم‌هایی، \کج{الگوریتم‌های تقریبی}\زیرنوشت{Approximation Algorithms} گفته می‌شود. یک الگوریتم تقریبی برای یک مسئله‌ی کمینه‌سازی دارای \کج{ضریب تقریب}\زیرنوشت{Approximation Factor} $\alpha$ است اگر به ازای همه‌ی ورودی‌ها، پاسخی حد‌اکثر $\alpha$ برابر پاسخ بهینه بیابد.


\قسمت{تعاریف و قضایای احتمال}

از آن‌جایی که بخشی از نتایج این رساله، بر پایه‌ی الگوریتم‌های تصادفی\زیرنوشت{Randomized Algorithms} و نامساوی‌های احتمالاتی به دست آمده‌اند، به بیان چند تعریف پایه و سپس قضایای مورد استفاده می‌پردازیم.

\شروع{فقرات}

\فقره \مهم{فرایند تصادفی}\زیرنوشت{Stochastic Process}:
به هر فرایندی که نتیجه آن نه به صورت قطعی که به صورت احتمالاتی مشخص می‌شود، فرایند تصادفی گفته می شود. به عنوان مثال، پرتاب یک سکه، یک فرایند تصادفی است؛ چراکه نتیجه‌ی آن به صورت احتمالاتی شیر یا خط است. 

\فقره \مهم{فضای نمونه}\زیرنوشت{Sample Space}:
به مجموعه‌ی نتیجه‌هایی که یک فرایند تصادفی می‌تواند اتخاذ کند، فضای نمونه‌ی آن فرایند تصادفی گفته می‌شود. به عنوان مثال، فضای نمونه‌ی فرایند تصادفی پرتاب سکه، مجموعه‌ی \{شیر، خط\} است.

\فقره \مهم{متغیر تصادفی}\زیرنوشت{Random Variable}:
تابعی از فضای نمونه‌ی یک فرایند تصادفی به مجموعه‌ی اعداد حقیقی، یک متغیر تصادفی است. به عنوان مثال، متغیر تصادفی $x_i$ را می‌توان معادل با شیر آمدن سکه پس از پرتاب $i$م  تعریف کرد که در صورت شیر آمدن سکه، مقدار $1$ و در غیر این صورت، مقدار $0$ می‌گیرد. در این رساله، برد همه‌ی متغیر‌های تصادفی، زیر‌مجموعه‌ای متناهی از مجموعه‌ی اعداد صحیح است.

\فقره \مهم{متغیر تصادفی شناسه}\زیرنوشت{Indicator Random Variable}:
یک متغیر تصادفی که برد آن $\{0, 1\}$ است (یک زیر‌مجموعه از فضای نمونه را به $1$ و باقی را به $0$ می‌برد)، یک متغیر تصادفی شناسه است. به بیانی دیگر، می‌توان گفت که $1$ بودن یک متغیر تصادفی شناسه معادل با اتفاق افتادن عضوی از زیر‌مجموعه‌ی مورد نظر است.

\فقره \مهم{امید ریاضی}\زیرنوشت{Expected Value}:
امید ریاضی یک متغیر تصادفی که برد آن، مجموعه‌ی متناهی $R$ است، به صورت زیر تعریف می‌شود:
$$E[X] = \Sigma_{x \in R} P(X=x) \times x$$

برای یک متغیر تصادفی شناسه بنا به تعریف داریم:
$$E[X] = P(X=1)\times 1 + P(X=0)\times 0 = P(X=1)$$

به بیان دیگر، برای یک متغیر تصادفی شناسه، امید ریاضی برابر است با احتمال $1$ شدن مقدار آن متغیر.

\فقره \مهم{واریانس}\زیرنوشت{Variance}:
واریانس معیاری است برای نشان دادن فاصله‌ی مقادیر یک متغیر تصادفی از امید ریاضی آن. به طور رسمی واریانس به صورت زیر تعریف می‌شود: 
$$var(X) = E[X^2] - {{(E[X])}^2}$$

هم‌چنین $\sigma(X)$ را برابر با $\sqrt{var(X)}$ تعریف می‌کنند و آن را \کج{انحراف معیار}\زیرنوشت{Standard Deviation} متغیر تصادفی $X$ می‌نامند.

\پایان{فقرات}
%

در ادامه به چند قضیه‌ی مهم و اساسی احتمالاتی اشاره می‌کنیم:

\شروع{قضیه}[خطی بودن امید ریاضی]
\label{theorem:expected-value}

امید ریاضی خطی است. به بیان دقیق‌تر، برای هر دو متغیر تصادفی $X$ و $Y$ و عدد ثابت $c$، روابط زیر برقرارند:
$$E[c X] = c E [X]$$
$$E[X + Y] = E[X] + E[Y]$$

\پایان{قضیه}

لازم به یادآوری است که تساوی‌های قضیه‌ی~\ref{theorem:expected-value} به ازای هر دو متغیر تصادفی $X$ و $Y$ برقرار است؛ چه مستقل باشند و چه نباشند.

\شروع{قضیه}[نامساوی‌های احتمالاتی]

در این قضیه، چند نامساوی احتمالاتی معروف که در تحلیل الگوریتم‌های احتمالی کاربرد دارند، بیان می‌شوند.

\شروع{فقرات}

\فقره اگر $X = \set{x_1, \ldots, x_k}$ مجموعه‌ای از متغیر‌های تصادفی باشد که برد همه‌ی آن‌ها $\set{0, 1}$ است، احتمال آن‌که مقدار حد‌اقل یک $x_i \in X$ برابر $1$ شود، حد‌اکثر $\Sigma_{x_i \in X} P(x_i = 1)$ است. دقت کنید که $\Sigma_{x_i \in X} P(x_i = 1)$، مجموع احتمال $1$ شدن این متغیر‌هاست.

\فقره \مهم{نامساوی مارکوف}\زیرنوشت{Markov Inequality}:
اگر برد متغیر تصادفی $X$، زیر‌مجموعه‌ای از اعداد حقیقی نامنفی باشد، آن‌گاه به ازای هر $a > 0$، داریم:
$$P(X \geq a) \leq {{E[X]} \over {a}}$$
یا به طور معادل، می‌توان نوشت به ازای هر $c > 0$:
$$P(X \geq c E[X]) \leq {{1} \over {c}}$$
به بیان دیگر، احتمال آن‌که مقدار $X$ از $c$ برابر مقدار امید ریاضی بیش‌تر شود، حد‌اکثر ${1} \over {c}$ است.

\فقره \مهم{نامساوی چبیچو}\زیرنوشت{Chebyshev Inequality}:
برای متغیر تصادفی $X$ با امید ریاضی و واریانس متناهی، به ازای هر $c > 0$ داریم:
$$P(|X - E[X]| \geq c \sigma(X)) \leq {{1} \over {c ^ 2}}$$
که در آن $\sigma(X) = \sqrt{var(X)}$.

\فقره \مهم{نامساوی چرنوف}\زیرنوشت{Chernoff Inequality}:
اگر $x_1, \ldots, x_n$
متغیرهای تصادفی مستقل از هم با دامنه‌ی $\set{0, 1}$  باشند و متغیر تصادفی $X$ به صورت 
$X = \Sigma_{i = 1}^n x_i$
تعریف گردد، آن گاه داریم:
$$P\set{X \geq (1+\epsilon)E[X]} < \left({{e^{\epsilon}}\over{(1+\epsilon)^{(1+\epsilon)}}}\right)^{E[X]}$$

هم چنین در ادامه‌ی این نامساوی، داریم:
$$(\frac{e^{\epsilon}}{(1+\epsilon)^{(1+\epsilon)}})^{E[X]} \leq e^{-{E[X]}\epsilon^2/3}$$

\پایان{فقرات}

\پایان{قضیه}

\قسمت{برنامه‌ریزی خطی}

هدف از یک برنامه‌ریزی خطی\زیرنوشت{Linear Programming (LP)}، یافتن یک بردار با مؤلفه‌های حقیقی است که در نامساوی‌های خطی داده‌شده در مسئله صدق کند و مقدار یک عبارت خطی را نیز کمینه (یا بیشینه) نماید. این عبارت خطی، \کج{تابع هدف}\زیرنوشت{Objective Function} نامیده می‌شود. فرض کنید $x_{1}, \ldots, x_{n}$ متغیر‌هایی با دامنه‌ی اعداد گویا باشند و
$$c_{j} \in \mathbb{Q}, \ \ b_i \in \mathbb{Q}, \ \ a_{i, j} \in \mathbb{Q} \ \ (1 \leq i \leq m, 1 \leq j \leq n)$$
یک برنامه‌ریزی خطی در حالت کلی به شکل زیر است:
\begin{latin}
\begin{alignat}{3}
    & \text{minimize}  \quad && \ {\sum_{j=1}^{n} {c_{j} x_{j}}} \notag \\
    & \text{subject to}  \quad 
		&& \!\!{\sum_{j=1}^{n} {a_{i, j} x_{j}} \geq b_{i}} && \qquad {\forall \ 1 \leq i \leq m} \notag \\
    		&&& x_{j} \geq 0 && \qquad {\forall \ 1 \leq j \leq n} \notag
\end{alignat}
\end{latin}

%$$Minimize \ \ \Sigma_{j=1}^{n} {c_{j} x_{j}}$$
%$$Subject\ to: \ \forall \ 1 \leq i \leq m \ \ \ \Sigma_{j=1}^{n} {a_{i, j} x_{j}} \geq b_{i}$$
%$$\ \ \ \ \ \forall \ 1 \leq j \leq n \ \ \ x_{j} \geq 0$$

در این برنامه‌ریزی خطی، عبارت خطی $\sum_{j=1}^{n} {c_{j} x_{j}}$، تابع هدف است. بدیهی است که اگر قصد بیشینه کردن تابع هدف را داشته‌باشیم، کافی است همه‌ی ضرایب $c_j$ در تابع هدف را قرینه کنیم. به این ترتیب، تابع هدفی به دست می‌آید که می‌خواهیم مقدار آن کمینه شود.

به یک بردار \کج{امکان‌پذیر} گفته می‌شود اگر در همه‌ی محدودیت‌های برنامه‌ریزی صدق کند. منظور از حل یک برنامه‌ریزی خطی، یافتن برداری امکان‌پذیر است که مقدار تابع هدف را کمینه کند. الگوریتم‌های کارایی برای حل برنامه‌ریزی خطی وجود دارند. یکی از بهترین الگوریتم‌های چند‌جمله‌ای که برای حل برنامه‌ریزی خطی ارائه شده، الگوریتم
\lr{interior-point}
است که در سال 1984 توسط کارمارکار پیشنهاد شده‌است~\cite{LP-poly}. زمان اجرای این الگوریتم از $O(n^{3.5} L )$ است که $n$ تعداد متغیر‌های برنامه‌ریزی خطی است و $L$ تعداد بیت‌هایی است که برای نمایش متغیر‌ها و محدودیت‌ها نیاز است.

\قسمت{برنامه‌ریزی صحیح}

برنامه‌ریزی صحیح\زیرنوشت{Integer Programming (IP)} یک برنامه‌ریزی خطی است که در آن، دامنه‌ی متغیر‌ها محدود به اعداد صحیح است. هر‌چند برنامه‌ریزی‌ خطی در زمان چند‌جمله‌ای قابل حل است، ولی می‌توان نشان داد که مسئله‌ی حل برنامه‌ریزی صحیح یک مسئله‌ی \سخت{} است. گفتنی است یک حالت خاص از مسئله‌ی برنامه‌ریزی صحیح که در آن دامنه‌ی متغیر‌ها تنها مجموعه‌ی دو عضوی $\set{0, 1}$ است، یکی از 21 مسئله‌ای است که کارپ به عنوان مسئله‌های \سخت{} معرفی کرده‌است~\cite{Karp}.

\قسمت{الگوریتم تقریبی بر پایه‌ی برنامه‌ریزی خطی}

برای بسیاری از مسئله‌های کمینه‌سازی هزینه، می‌توان یک برنامه‌ریزی صحیح معادل نوشت که دامنه‌ی متغیر‌های آن $\set{0, 1}$ است، ولی همان گونه که اشاره شد، با فرض $NP \neq P$، الگوریتم کارآیی برای حل برنامه‌ریزی صحیح وجود ندارد تا با کمک آن، مسئله‌ی بهینه‌سازی مورد نظر نیز حل شود. در چنین مواردی، یک راهکار رایج، این است که برنامه‌ریزی صحیح متناظر با مسئله‌ی مورد نظر به یک برنامه‌ریزی خطی با همان محدودیت‌ها تبدیل گردد و حل شود. بدیهی است که در برنامه‌ریزی خطی متناظر، دامنه‌ی متغیر‌ها به جای مجموعه‌ی دوعضوی $\set{0, 1}$، مجموعه‌ی همه‌ی اعداد گویای بازه‌ی $[0, 1]$ خواهد بود. فرض کنید جواب این برنامه‌ریزی خطی را بردار $OPT_{LP}$ بنامیم. یک ایده برای به دست آوردن الگوریتمی تقریبی آن است که پس از به دست آوردن $OPT_{LP}$، با گرد کردن مؤلفه‌های بردار $OPT_{LP}$ به یکی از دو روش زیر، پاسخی تقریبی برای برنامه‌ریزی صحیح مورد نظر به دست آید.

\شروع{فقرات}

\فقره \مهم{گرد کردن قطعی}

در این روش، یک عدد $0 < \alpha < 1$ انتخاب می‌شود. سپس هر متغیر که مقدار آن در $OPT_{LP}$ کم‌تر از $\alpha$  است، در برنامه‌ریزی صحیح مقدار $0$ می‌گیرد و مقدار سایر متغیر‌ها، همگی مقدار $1$. آن‌چه در این جا اهمیت دارد، انتخاب مقدار مناسبی برای $\alpha$ است، به گونه‌ای که بردار حاصل از گرد کردن، یک بردار امکان‌پذیر برای برنامه‌ریزی صحیح باشد. از آن‌جایی که در بردار جدید به دست آمده، مقدار هر متغیر حد‌اکثر ${{1} \over {\alpha}}$ برابر شده‌است، مقدار تابع هزینه نیز حد‌اکثر ${{1} \over {\alpha}}$ برابر خواهد شد و به این ترتیب، یک الگوریتم با ضریب تقریب ${{1} \over {\alpha}}$ خواهیم داشت.

\فقره \مهم{گرد کردن تصادفی}

در این روش، مقدار هر متغیر، نه به صورت قطعی بلکه با احتمالی به $1$ گرد می‌شود که این احتمال، خود تابعی است از مقدار همان متغیر در $OPT_{LP}$. بدیهی است که در این صورت، باید پذیرفت بردار جدید ممکن است امکان‌پذیر نباشد. در تحلیل یک الگوریتم تقریبی که بر پایه‌ی گرد کردن تصادفی طراحی شده، باید هم احتمال به دست آمدن برداری امکان‌پذیر بررسی شود و هم امید ریاضی مقدار تابع هزینه.

\پایان{فقرات}
